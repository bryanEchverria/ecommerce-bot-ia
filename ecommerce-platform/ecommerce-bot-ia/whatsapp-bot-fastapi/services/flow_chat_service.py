"""
Chat service integrado con Flow para pagos
Multi-tenant compatible
"""
import json
import os
from sqlalchemy.orm import Session
from models import FlowProduct, FlowPedido, FlowProductoPedido, FlowSesion
from services.flow_service import crear_orden_flow, get_client_id_for_phone
from services.backoffice_integration import (
    get_real_products_from_backoffice, 
    update_product_stock,
    get_product_by_name_fuzzy,
    get_tenant_from_phone,
    get_tenant_info,
    format_price
)
from datetime import datetime

# Smart flows integration
try:
    from services.smart_flows import detectar_intencion_con_gpt, ejecutar_flujo_inteligente
    SMART_FLOWS_AVAILABLE = True
except ImportError:
    SMART_FLOWS_AVAILABLE = False

# AI Improvements integration (TEMPORALMENTE DESHABILITADO)
try:
    from services.ai_improvements import process_message_with_ai_improvements
    AI_IMPROVEMENTS_AVAILABLE = False  # Force disable para que smart_flows funcione
except ImportError:
    AI_IMPROVEMENTS_AVAILABLE = False

# OpenAI integration (if available)
try:
    import openai
    openai.api_key = os.getenv("OPENAI_API_KEY")
    OPENAI_AVAILABLE = bool(os.getenv("OPENAI_API_KEY"))
except ImportError:
    OPENAI_AVAILABLE = False

# Multi-tenant client mapping with Flow support
TENANT_CLIENTS = {
    "+3456789012": {
        "name": "Green House",
        "type": "cannabis",
        "client_id": "green_house",
        "greeting": "üåø ¬°Hola! Bienvenido a Green House\nEspecialistas en productos can√°bicos premium."
    },
    "+1234567890": {
        "name": "Demo Company", 
        "type": "electronics",
        "client_id": "demo_company",
        "greeting": "üì± ¬°Hola! Demo Company - Electr√≥nicos de calidad"
    },
    "+5678901234": {
        "name": "Mundo Canino",
        "type": "pets",
        "client_id": "mundo_canino", 
        "greeting": "üêï ¬°Hola! Mundo Canino - Todo para tu mascota"
    },
    "+9876543210": {
        "name": "Test Store",
        "type": "clothing",
        "client_id": "test_store",
        "greeting": "üëï ¬°Hola! Test Store - Moda y estilo"
    },
}

def menu_principal(client_info, productos):
    """Muestra el cat√°logo de productos directamente en lugar de un men√∫ gen√©rico"""
    catalogo = f"üåø *{client_info['name']} - Cat√°logo disponible:*\n\n"
    for i, prod in enumerate(productos, 1):
        stock_status = "‚úÖ Disponible" if prod['stock'] > 5 else f"‚ö†Ô∏è Quedan {prod['stock']}"
        catalogo += f"{i}. **{prod['name']}** - ${prod['price']:,.0f}\n"
        catalogo += f"   {prod['description']}\n"
        catalogo += f"   {stock_status}\n\n"
    catalogo += "üí¨ *Para comprar:* Escribe el nombre del producto que quieres\n"
    catalogo += "üìù *Ejemplo:* 'Quiero Northern Lights' o solo 'Northern Lights'"
    return catalogo

def obtener_sesion(db: Session, telefono: str, tenant_id: str):
    """Obtiene o crea una sesi√≥n para el usuario"""
    sesion = db.query(FlowSesion).filter_by(telefono=telefono).first()
    if not sesion:
        sesion = FlowSesion(
            telefono=telefono,
            tenant_id=tenant_id,
            estado="INITIAL",
            datos="{}"
        )
        db.add(sesion)
        db.commit()
        db.refresh(sesion)
    return sesion

def guardar_sesion(db: Session, sesion, estado: str = None, datos: dict = None):
    """Guarda cambios en la sesi√≥n"""
    if estado:
        sesion.estado = estado
    if datos:
        sesion.datos = json.dumps(datos)
    sesion.updated_at = datetime.utcnow()
    db.commit()

def obtener_productos_cliente_real(db: Session, telefono: str, tenant_id: str = None):
    """
    Obtiene productos reales del backoffice en tiempo real
    COMPLETAMENTE DIN√ÅMICO - Multi-tenant compatible
    Puede usar n√∫mero de tel√©fono o tenant_id directamente
    """
    # Si no se proporciona tenant_id, obtenerlo del tel√©fono
    if tenant_id is None:
        tenant_id = get_tenant_from_phone(telefono, db)
    
    productos = get_real_products_from_backoffice(db, tenant_id)
    tenant_info = get_tenant_info(tenant_id, db)
    
    return productos, tenant_id, tenant_info

def procesar_mensaje_flow(db: Session, telefono: str, mensaje: str, tenant_id: str = None) -> str:
    """
    Procesa mensajes con l√≥gica de Flow integrada
    Multi-tenant compatible - consulta productos reales del backoffice
    """
    print(f"üöÄüöÄüöÄ ENTRANDO A PROCESAR_MENSAJE_FLOW: '{mensaje}' para tenant: {tenant_id}")
    # Si se proporciona tenant_id directamente (webhooks din√°micos), usarlo
    # Si no, obtener informaci√≥n del tenant basado en el tel√©fono (DIN√ÅMICO)
    if tenant_id is None:
        tenant_id = get_tenant_from_phone(telefono, db)
    
    tenant_info = get_tenant_info(tenant_id, db)
    
    # Mantener compatibilidad con c√≥digo existente
    client_info = {
        "name": tenant_info["name"],
        "type": tenant_info["type"],
        "greeting": tenant_info["greeting"]
    }
    
    if not client_info:
        return f"""‚ùå Cliente no configurado: {telefono}
        
‚úÖ Clientes v√°lidos:
‚Ä¢ +3456789012 ‚Üí Green House (can√°bicos)
‚Ä¢ +1234567890 ‚Üí Demo Company (electr√≥nicos)  
‚Ä¢ +5678901234 ‚Üí Mundo Canino (mascotas)
‚Ä¢ +9876543210 ‚Üí Test Store (ropa)

üß™ PRUEBA: Usa uno de estos n√∫meros"""

    sesion = obtener_sesion(db, telefono, tenant_id)
    datos_sesion = json.loads(sesion.datos) if sesion.datos else {}
    
    mensaje_lower = mensaje.lower().strip()
    
    # ========================================
    # PRIORIDAD ABSOLUTA: CONFIRMACI√ìN DE PEDIDOS
    # ========================================
    if sesion.estado == "ORDER_CONFIRMATION":
        print(f"‚ö†Ô∏è Estado ORDER_CONFIRMATION detectado, mensaje: '{mensaje}'")
        if any(word in mensaje_lower for word in ["s√≠", "si", "yes", "confirmo", "ok", "acepto"]):
            print(f"‚úÖ Confirmaci√≥n detectada!")
            datos = json.loads(sesion.datos)
            pedido_data = datos["pedido"]
            total = datos["total"]
            
            # Obtener datos del tenant para el pedido
            productos, tenant_id, tenant_info = obtener_productos_cliente_real(db, telefono, tenant_id)
            
            # Crear pedido en BD
            pedido = FlowPedido(
                telefono=telefono,
                tenant_id=tenant_id,
                total=total,
                estado="pendiente_pago"
            )
            db.add(pedido)
            db.commit()
            db.refresh(pedido)
            
            # Crear productos del pedido y actualizar stock en tiempo real
            for prod_id, item in pedido_data.items():
                # Actualizar stock en la tabla products del backoffice
                stock_actualizado = update_product_stock(db, prod_id, item["cantidad"], tenant_id)
                if not stock_actualizado:
                    return f"‚ùå Error: No hay suficiente stock de {item['nombre']}. Intenta con menos cantidad."
                
                producto_pedido = FlowProductoPedido(
                    pedido_id=pedido.id,
                    producto_id=prod_id,  # Usar string ID del backoffice
                    cantidad=item["cantidad"],
                    precio_unitario=item["precio"]
                )
                db.add(producto_pedido)
            
            db.commit()
            
            # Crear orden de pago en Flow
            descripcion = f"Pedido_{client_info['name']}_{pedido.id}"
            url_pago = crear_orden_flow(str(pedido.id), int(total), descripcion, tenant_id, db)
            
            # Preparar resumen del pedido con formato mejorado
            resumen_productos = ""
            for item in pedido_data.values():
                precio_formateado = format_price(item['precio'] * item['cantidad'], tenant_info['currency'])
                resumen_productos += f"‚Ä¢ {item['cantidad']} x {item['nombre']} = {precio_formateado}\n"
            
            total_formateado = format_price(total, tenant_info['currency'])
            respuesta = f"""üéâ **¬°Pedido confirmado!** #{pedido.id}

üõí **Tu compra:**
{resumen_productos}
üí∞ **Total: {total_formateado}**

üí≥ **Para completar tu pedido:**
üëâ Haz clic aqu√≠ para pagar: {url_pago}

‚è∞ **Despu√©s del pago:**
Escribe *"pagado"* y verificaremos tu pago autom√°ticamente."""
            
            guardar_sesion(db, sesion, "ORDER_SCHEDULING", {"pedido_id": pedido.id})
            return respuesta
            
        elif any(word in mensaje_lower for word in ["no", "cancelar", "cancel"]):
            guardar_sesion(db, sesion, "INITIAL", {})
            return "‚ùå **Pedido cancelado**\n\n¬øEn qu√© m√°s puedo ayudarte?"
        
        # Si escribe algo diferente durante la confirmaci√≥n
        else:
            return f"‚ùì No entend√≠ tu respuesta.\n\n‚ö° **Responde claramente:**\n‚Ä¢ **S√ç** - para confirmar el pedido\n‚Ä¢ **NO** - para cancelar\n\nüîÑ ¬øConfirmas tu pedido?"
    
    # Verificar pedido pendiente de pago
    pedido_pendiente = db.query(FlowPedido).filter_by(
        telefono=telefono,
        estado="pendiente_pago"
    ).first()
    
    # Si hay pedido pendiente y no est√° cancelando
    if pedido_pendiente and "cancelar" not in mensaje_lower:
        if mensaje_lower in ["pagado", "ya pagu√©", "pague", "pago"]:
            # Verificar estado en BD (actualizado por callback de Flow)
            pedido_actual = db.query(FlowPedido).filter_by(id=pedido_pendiente.id).first()
            if pedido_actual and pedido_actual.estado == "pagado":
                guardar_sesion(db, sesion, "INITIAL", {})
                return f"‚úÖ ¬°Pago confirmado! Tu pedido #{pedido_actual.id} ha sido procesado.\nGracias por tu compra. üôå"
            else:
                return f"‚ö†Ô∏è A√∫n no hemos recibido la confirmaci√≥n del pago para tu pedido #{pedido_pendiente.id}.\n\nSi ya pagaste, el proceso puede tomar unos minutos."
        
        return f"Tu pedido #{pedido_pendiente.id} est√° pendiente de pago. Si ya pagaste escribe *pagado*, o escribe *cancelar pedido* para anularlo."
    
    # Cancelar pedido
    if "cancelar pedido" in mensaje_lower or "cancelar" in mensaje_lower:
        if pedido_pendiente:
            pedido_pendiente.estado = "cancelado"
            db.commit()
            guardar_sesion(db, sesion, "INITIAL", {})
            productos, tenant_id, tenant_info = obtener_productos_cliente_real(db, telefono, tenant_id)
            return f"‚ùå Tu pedido #{pedido_pendiente.id} ha sido *cancelado*.\n" + menu_principal(tenant_info, productos)
        else:
            productos, tenant_id, tenant_info = obtener_productos_cliente_real(db, telefono, tenant_id)
            return "No tienes pedidos pendientes para cancelar.\n" + menu_principal(tenant_info, productos)
    
    # ========================================
    # ELIMINADA DETECCI√ìN HARDCODEADA - AHORA TODO ES DIN√ÅMICO CON GPT
    # El sistema GPT completamente din√°mico maneja todas las intenciones
    # ========================================

    # ========================================
    # PRIORIDAD 2: SISTEMA DE IA MEJORADO CON CONTEXTO  
    # ========================================
    if AI_IMPROVEMENTS_AVAILABLE and OPENAI_AVAILABLE:
        try:
            print(f"ü§ñ Iniciando sistema IA mejorado para: '{mensaje}'")
            
            # Obtener productos para el contexto
            productos, tenant_id, tenant_info = obtener_productos_cliente_real(db, telefono, tenant_id)
            
            if productos:
                # Procesar mensaje con IA mejorada
                respuesta_ia, metadata_ia = process_message_with_ai_improvements(
                    db, telefono, tenant_id, mensaje, productos, tenant_info
                )
                
                print(f"‚úÖ IA Mejorada respondi√≥ (confianza: {metadata_ia.get('intent_confidence', 0):.2f}, tiempo: {metadata_ia.get('response_time_ms', 0)}ms)")
                
                # Si la confianza es alta, usar la respuesta de IA (umbral reducido para testing)
                if metadata_ia.get('intent_confidence', 0) > 0.3:
                    return respuesta_ia
                
                # Si la confianza es media, continuar con smart flows como backup
                print(f"‚ö†Ô∏è Confianza media, continuando con smart flows...")
                
        except Exception as e:
            print(f"‚ùå Error en sistema IA mejorado: {e}")
            # Continuar con smart flows como fallback
    
    # ========================================
    # PRIORIDAD 3: SISTEMA DE FLUJOS INTELIGENTES (FALLBACK)
    # ========================================
    if SMART_FLOWS_AVAILABLE and OPENAI_AVAILABLE:
        try:
            print(f"üß† Iniciando detecci√≥n inteligente para: '{mensaje}'")
            
            # MANEJO DIN√ÅMICO DE CONTEXTO DE CONVERSACI√ìN USANDO GPT
            # GPT decide si el mensaje es una continuaci√≥n de conversaci√≥n bas√°ndose en el contexto
            contexto_conversacion = _manejar_contexto_dinamico_con_gpt(
                db, sesion, mensaje, datos_sesion, telefono, tenant_id
            )
            
            if contexto_conversacion:
                print(f"üîÑ GPT detect√≥ continuaci√≥n de conversaci√≥n: {contexto_conversacion['accion']}")
                return contexto_conversacion['respuesta']
            
            # Obtener productos para el contexto
            productos, tenant_id, tenant_info = obtener_productos_cliente_real(db, telefono, tenant_id)
            
            if productos:
                # GPT detecta la intenci√≥n espec√≠fica
                deteccion = detectar_intencion_con_gpt(mensaje, productos, tenant_info)
                print(f"üéØ GPT detect√≥: {deteccion}")
                
                # Ejecutar flujo espec√≠fico seg√∫n detecci√≥n
                if deteccion["intencion"] in ["saludo", "consulta_producto", "consulta_categoria", "consulta_catalogo", "intencion_compra"]:
                    print(f"‚úÖ Ejecutando flujo espec√≠fico para: {deteccion['intencion']}")
                    
                    print(f"üöÄ Ejecutando flujo inteligente para: {deteccion['intencion']}")
                    respuesta_inteligente = ejecutar_flujo_inteligente(deteccion, productos, tenant_info)
                    print(f"‚úÖ Flujo inteligente retorn√≥: {respuesta_inteligente[:100]}...")
                    print(f"üìù Respuesta generada: {len(respuesta_inteligente)} caracteres")
                    
                    # Actualizar sesi√≥n seg√∫n el tipo de consulta
                    if deteccion["intencion"] == "consulta_categoria":
                        # Guardar la categor√≠a consultada para mantener contexto
                        categoria_consultada = deteccion.get("categoria")
                        if categoria_consultada:
                            guardar_sesion(db, sesion, "BROWSING", {"ultima_categoria": categoria_consultada})
                        else:
                            guardar_sesion(db, sesion, "BROWSING", {})
                    elif deteccion["intencion"] == "consulta_catalogo":
                        guardar_sesion(db, sesion, "BROWSING", {})
                    elif deteccion["intencion"] == "intencion_compra":
                        # No actualizar sesi√≥n aqu√≠, se maneja en la l√≥gica de compras m√°s abajo
                        pass
                    
                    print("üéâ Flujo inteligente completado exitosamente")
                    return respuesta_inteligente
                    
        except Exception as e:
            print(f"‚ùå Error en flujos inteligentes: {e}")
            import traceback
            traceback.print_exc()
    
    # SOLO SISTEMA GPT - Sin condiciones hardcodeadas
    # El sistema GPT debe manejar todos los casos: saludos, consultas de productos, etc.
    
    # Si llegamos aqu√≠, el sistema GPT no manej√≥ el mensaje, usar fallback GPT
    
    # ========================================
    # SISTEMA DIN√ÅMICO ESCALABLE CON CONFIGURACI√ìN DE TENANT
    # ========================================
    
    print(f"üîÑ Activando sistema din√°mico escalable para tenant: {tenant_id}")
    
    try:
        # Importar sistema din√°mico
        from services.dynamic_tenant_bot import process_message_with_dynamic_ai
        
        # Obtener productos y informaci√≥n del tenant
        productos, tenant_id, tenant_info = obtener_productos_cliente_real(db, telefono, tenant_id)
        
        # Procesar con IA din√°mica personalizada
        respuesta_dinamica = process_message_with_dynamic_ai(
            db=db,
            telefono=telefono,
            mensaje=mensaje,
            tenant_id=tenant_id,
            productos=productos,
            tenant_info=tenant_info
        )
        
        print(f"‚úÖ Sistema din√°mico respondi√≥ para {tenant_id}")
        return respuesta_dinamica
        
    except Exception as e:
        print(f"‚ùå Error en sistema din√°mico para {tenant_id}: {e}")
        import traceback
        traceback.print_exc()
        
        # Fallback seguro con informaci√≥n real del tenant
        productos, tenant_id, tenant_info = obtener_productos_cliente_real(db, telefono, tenant_id)
        from services.dynamic_tenant_bot import get_dynamic_greeting_with_products
        
        return get_dynamic_greeting_with_products(tenant_info, productos)

def _manejar_contexto_dinamico_con_gpt(db: Session, sesion, mensaje: str, datos_sesion: dict, telefono: str, tenant_id: str):
    """
    Maneja el contexto de conversaci√≥n de manera 100% din√°mica usando GPT
    Sin l√≥gica hardcodeada - GPT decide si el mensaje es una continuaci√≥n
    """
    if not OPENAI_AVAILABLE:
        return None
    
    try:
        import openai
        client = openai.OpenAI()
        
        # Obtener informaci√≥n del contexto actual
        estado_sesion = sesion.estado
        contexto_anterior = datos_sesion.get('ultima_categoria', '')
        ultima_respuesta = datos_sesion.get('ultima_respuesta', '')
        
        # Solo procesar si hay contexto previo
        if not contexto_anterior and estado_sesion != "BROWSING":
            return None
        
        # PROMPT DIN√ÅMICO PARA AN√ÅLISIS DE CONTEXTO
        contexto_prompt = f"""Analiza si este mensaje contin√∫a una conversaci√≥n previa.

CONVERSACI√ìN PREVIA:
- Estado: {estado_sesion}
- Categor√≠a anterior: {contexto_anterior or 'ninguna'}
- √öltima respuesta: {ultima_respuesta[:100] if ultima_respuesta else 'ninguna'}

MENSAJE ACTUAL: "{mensaje}"

TAREA: ¬øEs este mensaje una continuaci√≥n de la conversaci√≥n anterior?

AN√ÅLISIS:
- Si el usuario responde afirmativamente ‚Üí puede ser continuaci√≥n
- Si cambia de tema completamente ‚Üí nueva conversaci√≥n
- Si hace seguimiento al tema anterior ‚Üí continuaci√≥n

RESPONDE UNA de estas opciones:
- "continuar_categoria" - continuar con la categor√≠a que se consult√≥ antes
- "continuar_catalogo" - mostrar cat√°logo general
- "nueva_conversacion" - iniciar nueva conversaci√≥n

RESPUESTA:"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": contexto_prompt}],
            temperature=0.1,
            max_tokens=20
        )
        
        decision_gpt = response.choices[0].message.content.strip().lower()
        print(f"üß† GPT decisi√≥n de contexto: '{decision_gpt}'")
        
        # Procesar decisi√≥n de GPT
        if decision_gpt == "continuar_categoria" and contexto_anterior:
            print(f"üîÑ GPT: Continuando con categor√≠a '{contexto_anterior}'")
            
            # Obtener productos y ejecutar consulta de categor√≠a
            productos, _, tenant_info = obtener_productos_cliente_real(db, telefono, tenant_id)
            from services.smart_flows import ejecutar_consulta_categoria
            respuesta = ejecutar_consulta_categoria(contexto_anterior, productos, tenant_info)
            
            # Mantener contexto
            guardar_sesion(db, sesion, "BROWSING", {
                "ultima_categoria": contexto_anterior,
                "ultima_respuesta": respuesta[:200]
            })
            
            return {
                "accion": "continuar_categoria",
                "respuesta": respuesta
            }
            
        elif decision_gpt == "continuar_catalogo":
            print(f"üîÑ GPT: Continuando con cat√°logo completo")
            
            # Mostrar cat√°logo completo
            productos, _, tenant_info = obtener_productos_cliente_real(db, telefono, tenant_id)
            from services.smart_flows import ejecutar_consulta_catalogo
            respuesta = ejecutar_consulta_catalogo(productos, tenant_info)
            
            # Actualizar contexto
            guardar_sesion(db, sesion, "BROWSING", {
                "ultima_respuesta": respuesta[:200]
            })
            
            return {
                "accion": "continuar_catalogo", 
                "respuesta": respuesta
            }
        
        else:
            print(f"üîÑ GPT: Nueva conversaci√≥n - no hay continuaci√≥n")
            return None
            
    except Exception as e:
        print(f"‚ùå Error en manejo din√°mico de contexto: {e}")
        return None